{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<EOF>', '<PAD>', 'want', '.', 'shopping', 'i', 'will', 'shop', 'to', 'go']\n"
     ]
    }
   ],
   "source": [
    "data_x = \"i want to go shopping .\"\n",
    "data_y = \"i will go to shop .\"\n",
    "data_x_split = data_x.split(' ')\n",
    "data_y_split = data_y.split(' ')\n",
    "\n",
    "data = data_x_split + data_y_split\n",
    "\n",
    "data_list = [\"<EOF>\", \"<PAD>\"]\n",
    "data_list.extend(list(set(data)))\n",
    "\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = len(data_list)\n",
    "hidden_num = 4\n",
    "learning_rate = 0.01\n",
    "train_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 2 8 9 4 3 0 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 5 6 9 8 7 3 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_x_idx = np.array([list_idx for x_idx, x_data in enumerate(data_x_split) for list_idx, list_data in enumerate(data_list) if list_data == x_data])\n",
    "data_y_idx = np.array([list_idx for y_idx, y_data in enumerate(data_y_split) for list_idx, list_data in enumerate(data_list) if list_data == y_data])\n",
    "\n",
    "data_x_idx = np.append(data_x_idx,0)\n",
    "data_y_idx = np.append(data_y_idx,0)\n",
    "\n",
    "ones_y_list = np.array(np.ones_like(data_x_idx[:len(data_x_idx)-1]))\n",
    "data_y_idx = np.append(ones_y_list,data_y_idx)\n",
    "\n",
    "data_x_idx = np.append(data_x_idx, np.ones(len(data_y_split), dtype=np.int64))\n",
    "\n",
    "\n",
    "data_x_one_hot = np.zeros((len(data_x_idx), class_num))\n",
    "data_y_one_hot = np.zeros((len(data_y_idx), class_num))\n",
    "\n",
    "data_x_one_hot[np.arange(len(data_x_idx)), data_x_idx] = 1\n",
    "data_y_one_hot[np.arange(len(data_y_idx)), data_y_idx] = 1\n",
    "\n",
    "data_x_one_hot = np.array(data_x_one_hot, dtype='f')\n",
    "data_y_one_hot = np.array(data_y_one_hot, dtype='f')\n",
    "\n",
    "print(data_x_idx)\n",
    "print(data_y_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, class_num])\n",
    "y = tf.placeholder(tf.float32, [None, class_num])\n",
    "\n",
    "input_w = tf.get_variable(name='input_w', shape=[class_num, hidden_num], initializer=tf.contrib.layers.xavier_initializer())\n",
    "output_w = tf.get_variable(name=\"output_w\", shape=[hidden_num, class_num], initializer=tf.contrib.layers.xavier_initializer())\n",
    "prev_w = tf.get_variable(name=\"prev_w\", shape=[class_num, hidden_num], initializer=tf.contrib.layers.xavier_initializer())\n",
    "hidden_bias = tf.get_variable(name=\"hidden_bias\", shape=[hidden_num], initializer=tf.contrib.layers.xavier_initializer())\n",
    "output_bias = tf.get_variable(name=\"output_bias\", shape=[class_num], initializer=tf.contrib.layers.xavier_initializer())\n",
    "next_h = tf.get_variable(name=\"next_h\", shape=[hidden_num], initializer=tf.zeros_initializer())\n",
    "\n",
    "prev_h = tf.get_variable(name=\"prev_h\", shape=[class_num], initializer=tf.zeros_initializer())\n",
    "output = tf.get_variable(name=\"output\", shape=(0))\n",
    "\n",
    "def RnnCell(input_x, prev):\n",
    "    input_data = tf.reshape(input_x, [-1, class_num])\n",
    "    prev_h = tf.reshape(prev, [-1, class_num])\n",
    "    hidden = tf.tanh(tf.matmul(input_data, input_w) + tf.matmul(prev_h, prev_w) + hidden_bias)\n",
    "    output = tf.matmul(hidden, output_w) + output_bias\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "o_list = [prev_h]\n",
    "\n",
    "for i in range(len(data_y_one_hot)):\n",
    "    x_slice = tf.slice(x, [i,0], [1, -1])\n",
    "    o_list.append(RnnCell(x_slice, o_list[i]))\n",
    "\n",
    "output = o_list[1]\n",
    "\n",
    "for i in range(len(o_list[2:])):\n",
    "    output = tf.concat([output, o_list[i+2]], axis=0)\n",
    "    \n",
    "result = output\n",
    "\n",
    "#data = output_y\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 1.7090533\n",
      "cost: 1.3877918\n",
      "cost: 1.1745446\n",
      "cost: 1.0187148\n",
      "cost: 0.915328\n",
      "cost: 0.8345891\n",
      "cost: 0.9959867\n",
      "cost: 0.8285627\n",
      "cost: 0.77854216\n",
      "cost: 0.73809487\n",
      "cost: 0.71746594\n",
      "cost: 0.69847906\n",
      "cost: 0.6799298\n",
      "cost: 0.66148144\n",
      "cost: 0.6427742\n",
      "cost: 0.6238647\n",
      "cost: 0.605322\n",
      "cost: 0.5874999\n",
      "cost: 0.5704774\n",
      "cost: 0.5542797\n",
      "Accuracy: 0.7692308\n",
      "[1 1 1 1 1 1 1 6 9 8 3 3 3]\n",
      "['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'will', 'go', 'to', '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    prediction = tf.equal(tf.argmax(result,1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "    \n",
    "    for step in range(20):\n",
    "        c = 0\n",
    "        for i in range(train_size):\n",
    "            _, c, pre_result = sess.run([optimizer, cost, tf.argmax(result, 1)], {x:data_x_one_hot, y:data_y_one_hot})\n",
    "\n",
    "            if c<0.5:\n",
    "                learning_rate = 0.001\n",
    "        print(\"cost:\",c)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy.eval({x:data_x_one_hot, y:data_y_one_hot}))\n",
    "    \n",
    "    pre_result = sess.run(tf.argmax(result,1), {x:data_x_one_hot, y:data_y_one_hot})\n",
    "    print(pre_result)\n",
    "    print([data_list[i]for i in pre_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
